import os
from typing import Dict, List, Optional
import time
from pathlib import Path

import pandas as pd
import tushare as ts

from config import CSV_FILE, INITIAL_CAPITAL, DOCS_DIR, REPORT_YEAR

import os
TUSHARE_TOKEN = os.environ.get("TUSHARE_TOKEN", "")

# æ³¨æ„ï¼šç¼“å­˜åŠŸèƒ½å·²ç§»é™¤ï¼Œå› ä¸ºç°åœ¨ä½¿ç”¨æŒä»“æˆæœ¬è€Œéæ”¶ç›˜ä»·
# CACHE_DIR å®šä¹‰ä¿ç•™ä»¥é¿å…é”™è¯¯ï¼Œä½†ä¸å†ä¸»åŠ¨åˆ›å»ºç›®å½•
CACHE_DIR = Path(DOCS_DIR) / ".cache"
# CACHE_DIR.mkdir(exist_ok=True)  # å·²æ³¨é‡Šï¼šä¸å†éœ€è¦ç¼“å­˜åŠŸèƒ½


def _ts_code(code: str) -> str:
    """å°†6ä½è‚¡ç¥¨ä»£ç è½¬ä¸ºTushareæ ¼å¼"""
    if code.startswith('6'):
        return f"{code}.SH"
    else:
        return f"{code}.SZ"


def _read_csv(csv_path: str) -> pd.DataFrame:
    """
    è¯»å–äº¤å‰²å•CSVï¼ˆpairæ ¼å¼ï¼šä¸€è¡ŒåŒ…å«ä¹°å…¥ä¸å–å‡ºä¿¡æ¯ï¼‰ï¼Œå¹¶è¿”å›DataFrameã€‚
    ä»…åšè¯»å–ï¼Œä¸åšé‡å‘½åæˆ–æ ¡éªŒã€‚
    """
    last_err = None
    for enc in ("utf-8-sig", "utf-8", "gbk", "gb2312"):
        try:
            df = pd.read_csv(csv_path, encoding=enc)
            # è§„èŒƒä»£ç åˆ—ä¸º6ä½å­—ç¬¦ä¸²ï¼Œé¿å…å‰å¯¼0ä¸¢å¤±å¯¼è‡´åç»­æ— æ³•åŒ¹é…Tushareç»“æœ
            if "code" in df.columns:
                def _norm_code(v):
                    if pd.isna(v):
                        return None
                    s = str(v).strip()
                    if s.endswith('.0'):
                        s = s[:-2]
                    digits = ''.join(ch for ch in s if ch.isdigit())
                    if not digits:
                        return s
                    return digits[-6:].zfill(6)
                df["code"] = df["code"].apply(_norm_code)
            return df
        except UnicodeDecodeError as e:
            last_err = e
            continue
    raise last_err if last_err else RuntimeError("æ— æ³•è¯»å–CSVæ–‡ä»¶")


def _parse_dates(df: pd.DataFrame) -> pd.DataFrame:
    """
    è§£æä¹°å–æ—¶é—´åˆ—ä¸ºæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ã€‚ä¼˜å…ˆä½¿ç”¨ FROM_UNIXTIME æ—¶é—´åˆ—ï¼›
    ä¸å­˜åœ¨æ—¶å›é€€åˆ° start/end åˆ—ã€‚è‹¥ç¼ºå¤±åˆ™ç»“æœä¸º NaTã€‚
    """
    # ä¹°å…¥æ—¶é—´
    if "FROM_UNIXTIME(buy_time)" in df.columns:
        b = pd.to_datetime(df["FROM_UNIXTIME(buy_time)"], errors="coerce")
    elif "buy_time" in df.columns:
        b = pd.to_datetime(df["buy_time"], errors="coerce")
    elif "start" in df.columns:
        b = pd.to_datetime(df["start"], errors="coerce")
    else:
        b = pd.to_datetime(pd.Series([pd.NaT] * len(df)))

    # å–å‡ºæ—¶é—´
    if "FROM_UNIXTIME(sell_time)" in df.columns:
        s = pd.to_datetime(df["FROM_UNIXTIME(sell_time)"], errors="coerce")
    elif "sell_time" in df.columns:
        s = pd.to_datetime(df["sell_time"], errors="coerce")
    elif "end" in df.columns:
        s = pd.to_datetime(df["end"], errors="coerce")
    else:
        s = pd.to_datetime(pd.Series([pd.NaT] * len(df)))

    df = df.copy()
    df["buy_dt"] = b
    df["sell_dt"] = s
    df["buy_date"] = b.dt.strftime("%Y-%m-%d")
    df["sell_date"] = s.dt.strftime("%Y-%m-%d")
    return df


def calculate_daily_asset_distribution(
    csv_path: Optional[str] = None,
    initial_capital: Optional[float] = None,
    max_days: Optional[int] = None,
    report_year: Optional[str] = "AUTO",
) -> pd.DataFrame:
    """
    åŸºäºäº¤å‰²å•ï¼ˆpairæ ¼å¼ï¼‰è®¡ç®—æ¯æ—¥èµ„äº§åˆ†ç±»å æ¯”ï¼ˆè‚¡ç¥¨/ç°é‡‘ï¼‰ã€‚

    æ ¸å¿ƒé€»è¾‘ï¼š
    - å…ˆæŒ‰å¤©è®¡ç®—æ¯åªè‚¡ç¥¨çš„æœŸæœ«æŒä»“è‚¡æ•°ï¼ˆç´¯è®¡ä¹°å…¥è‚¡æ•° - ç´¯è®¡å–å‡ºè‚¡æ•°ï¼Œå–å‡ºå½“æ—¥ä¸è®¡å…¥æŒä»“ï¼‰ã€‚
    - ä½¿ç”¨æŒä»“æˆæœ¬è®¡ç®—å½“æ—¥è‚¡ç¥¨å¸‚å€¼ = Î£(æŒä»“è‚¡æ•° Ã— æŒä»“å¹³å‡æˆæœ¬)ã€‚
    - å½“æ—¥ç°é‡‘ = åˆå§‹èµ„é‡‘ - æˆªæ­¢å½“æ—¥ç´¯è®¡ä¹°å…¥é‡‘é¢ + ç´¯è®¡å–å‡ºé‡‘é¢ã€‚
    - å½“æ—¥æ€»èµ„äº§ = è‚¡ç¥¨å¸‚å€¼ + ç°é‡‘ã€‚
    - å æ¯”ï¼šè‚¡ç¥¨å æ¯”=è‚¡ç¥¨å¸‚å€¼/æ€»èµ„äº§ï¼Œç°é‡‘å æ¯”=ç°é‡‘/æ€»èµ„äº§ã€‚

    å‚æ•°:
        csv_path: äº¤å‰²å•CSVè·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨ config.CSV_FILE
        initial_capital: åˆå§‹èµ„é‡‘ï¼ˆå…ƒï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ config.INITIAL_CAPITAL
        max_days: ä»…è®¡ç®—å‰Nå¤©çš„æ•°æ®ï¼Œç”¨äºåŠ é€Ÿæ¼”ç¤º
        report_year: æŠ¥å‘Šå¹´ä»½ï¼ˆå¦‚"2015"ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ config.REPORT_YEAR
                    è®¾ç½®ååªè¿”å›è¯¥å¹´ä»½çš„æ•°æ®ï¼Œä½†ä¼šæ­£ç¡®è®¡ç®—æœŸåˆæŒä»“

    è¿”å›:
        pd.DataFrame: æ¯æ—¥èµ„äº§åˆ†å¸ƒæ•°æ®ï¼Œindex=date(å­—ç¬¦ä¸²æ ¼å¼ YYYY-MM-DD)
            columns=['total_assets', 'stock_pct', 'cash_pct']
            - total_assets: æ€»èµ„äº§ï¼ˆå…ƒï¼‰ï¼Œè‚¡ç¥¨å¸‚å€¼+ç°é‡‘
            - stock_pct: è‚¡ç¥¨å æ¯”ï¼ˆ%ï¼‰
            - cash_pct: ç°é‡‘å æ¯”ï¼ˆ%ï¼‰
    """
    csv_path = str(csv_path or CSV_FILE)
    ini = float(initial_capital if initial_capital is not None else INITIAL_CAPITAL)
    # report_year="AUTO" è¡¨ç¤ºä½¿ç”¨configé…ç½®ï¼ŒNone è¡¨ç¤ºä¸é™åˆ¶å¹´ä»½
    if report_year == "AUTO":
        report_year = REPORT_YEAR
    if ini <= 0:
        raise ValueError("initial_capital å¿…é¡»ä¸ºæ­£æ•°")

    raw = _read_csv(csv_path)
    df = _parse_dates(raw)

    # æ³¨æ„ï¼šä»·æ ¼å¼‚å¸¸è¿‡æ»¤å·²ç§»è‡³Excel->CSVè½¬æ¢é˜¶æ®µï¼ˆdata/reader.pyï¼‰
    # æ­¤å¤„ç›´æ¥ä½¿ç”¨æ¸…æ´—åçš„CSVæ•°æ®

    # å‡†å¤‡é‡‘é¢åˆ—
    buy_money_col = "buy_money" if "buy_money" in df.columns else None
    sell_money_col = "sell_money" if "sell_money" in df.columns else None
    if buy_money_col is None or sell_money_col is None:
        raise ValueError("CSVç¼ºå°‘ buy_money æˆ– sell_money åˆ—")

    df[buy_money_col] = pd.to_numeric(df[buy_money_col], errors="coerce").fillna(0.0)
    df[sell_money_col] = pd.to_numeric(df[sell_money_col], errors="coerce").fillna(0.0)
    # è‚¡æ•°åˆ—ï¼ˆç”¨äºè®¡ç®—æŒä»“è‚¡æ•°ï¼‰
    buy_num_col = "buy_number" if "buy_number" in df.columns else None
    sell_num_col = "sell_number" if "sell_number" in df.columns else None
    if buy_num_col is None or sell_num_col is None:
        raise ValueError("CSVç¼ºå°‘ buy_number æˆ– sell_number åˆ—")
    df[buy_num_col] = pd.to_numeric(df[buy_num_col], errors="coerce").fillna(0.0)
    df[sell_num_col] = pd.to_numeric(df[sell_num_col], errors="coerce").fillna(0.0)
    # ä»£ç åˆ—
    code_col = "code" if "code" in df.columns else None
    if code_col is None:
        raise ValueError("CSVç¼ºå°‘ code åˆ—")

    # æŒ‰æ—¥èšåˆä¹°å…¥/å–å‡ºé‡‘é¢
    buy_by_day = (
        df.dropna(subset=["buy_dt"])
        .groupby(df["buy_dt"].dt.strftime("%Y-%m-%d"))[buy_money_col]
        .sum()
        .sort_index()
    )
    sell_by_day = (
        df.dropna(subset=["sell_dt"])
        .groupby(df["sell_dt"].dt.strftime("%Y-%m-%d"))[sell_money_col]
        .sum()
        .sort_index()
    )

    # ç”Ÿæˆå®Œæ•´æ—¥æœŸåºåˆ—
    # ä½¿ç”¨ä¹°å…¥å’Œå–å‡ºæ—¥æœŸçš„å¹¶é›†ï¼Œç¡®ä¿æ‰€æœ‰äº¤æ˜“éƒ½è¢«ç»Ÿè®¡
    all_dates = pd.to_datetime(list(set(buy_by_day.index).union(set(sell_by_day.index))))
    if len(all_dates) == 0:
        return pd.DataFrame()
    start = all_dates.min().date()
    end = all_dates.max().date()
    date_range = pd.date_range(start=start, end=end, freq="D").strftime("%Y-%m-%d")
    if isinstance(max_days, int) and max_days > 0:
        date_range = date_range[:max_days]

    # ç´¯è®¡ä¹°å–é‡‘é¢ï¼ˆæŒ‰æ—¥æœŸå¯¹é½ï¼‰
    cum_buy = buy_by_day.reindex(date_range, fill_value=0.0).cumsum()
    cum_sell = sell_by_day.reindex(date_range, fill_value=0.0).cumsum()

    # è®¡ç®—æ¯æ—¥æŒä»“è‚¡æ•°ï¼ˆæŒ‰è‚¡ç¥¨ä»£ç ï¼‰
    buys_qty = (
        df.dropna(subset=["buy_dt"]).groupby([df["buy_dt"].dt.strftime("%Y-%m-%d"), code_col])[buy_num_col].sum()
    )
    sells_qty = (
        df.dropna(subset=["sell_dt"]).groupby([df["sell_dt"].dt.strftime("%Y-%m-%d"), code_col])[sell_num_col].sum()
    )
    # é€è§†ä¸ºæ—¥æœŸÃ—ä»£ç 
    buy_qty_daily = buys_qty.unstack(fill_value=0.0).reindex(date_range, fill_value=0.0)
    sell_qty_daily = sells_qty.unstack(fill_value=0.0).reindex(date_range, fill_value=0.0)
    # ç´¯è®¡åˆ°å½“æ—¥ï¼ˆEOD æŒä»“ï¼‰
    cum_buy_qty = buy_qty_daily.cumsum()
    cum_sell_qty = sell_qty_daily.cumsum()
    holdings_qty = (cum_buy_qty - cum_sell_qty).clip(lower=0.0)

    # è®¡ç®—æŒä»“æˆæœ¬ï¼ˆä½¿ç”¨ç®€å•çš„é‡‘é¢ç´¯åŠ æ³•ï¼Œä¸å‚è€ƒè„šæœ¬ä¸€è‡´ï¼‰
    # æŒä»“æˆæœ¬ = ç´¯è®¡ä¹°å…¥é‡‘é¢ - å·²å–å‡ºè‚¡ç¥¨çš„ä¹°å…¥æˆæœ¬
    # 
    # æ³¨æ„ï¼šè¿™é‡ŒæŒ‰æ—¥æœŸå’Œä»£ç èšåˆå–å‡ºé‡‘é¢ï¼ˆä½†å®é™…ä¸Šæˆ‘ä»¬éœ€è¦çš„æ˜¯å–å‡ºè‚¡ç¥¨çš„ä¹°å…¥æˆæœ¬ï¼‰
    # ç”±äºäº¤å‰²å•æ˜¯é…å¯¹æ ¼å¼ï¼ˆæ¯è¡ŒåŒ…å«ä¹°å…¥å’Œå–å‡ºï¼‰ï¼Œå–å‡ºæ—¶å‡å»çš„æ˜¯è¯¥ç¬”äº¤æ˜“çš„buy_money
    
    # æŒ‰æ—¥æœŸèšåˆï¼šä¹°å…¥æ—¶å¢åŠ æŒä»“æˆæœ¬ï¼Œå–å‡ºæ—¶å‡å°‘æŒä»“æˆæœ¬
    sells_cost = (
        df.dropna(subset=["sell_dt"]).groupby(df["sell_dt"].dt.strftime("%Y-%m-%d"))[buy_money_col].sum()
    )
    sells_cost_daily = sells_cost.reindex(date_range, fill_value=0.0)
    
    # ç´¯è®¡æŒä»“æˆæœ¬ = ç´¯è®¡ä¹°å…¥ - ç´¯è®¡å–å‡ºçš„ä¹°å…¥æˆæœ¬
    cum_position_cost = (buy_by_day.reindex(date_range, fill_value=0.0).cumsum() 
                        - sells_cost_daily.cumsum())
    
    # è‚¡ç¥¨å¸‚å€¼ = æŒä»“æˆæœ¬ï¼ˆä½¿ç”¨ä¹°å…¥æˆæœ¬ï¼Œä¸ä½¿ç”¨å¸‚ä»·ï¼‰
    stock_value = cum_position_cost
    # ç°é‡‘ = åˆå§‹èµ„é‡‘ - ç´¯è®¡ä¹°å…¥é‡‘é¢ + ç´¯è®¡å–å‡ºé‡‘é¢
    cash_value = ini - cum_buy + cum_sell
    
    # ä¿®æ­£ï¼šå¦‚æœåˆå§‹èµ„é‡‘è®¾ç½®ä¸è¶³å¯¼è‡´ç°é‡‘ä¸ºè´Ÿæ•°
    # éœ€è¦åŠ¨æ€è°ƒæ•´åˆå§‹èµ„é‡‘ï¼Œä½¿ç°é‡‘å§‹ç»ˆéè´Ÿ
    min_cash = cash_value.min()
    if min_cash < 0:
        # è°ƒæ•´åˆå§‹èµ„é‡‘ï¼Œç¡®ä¿æœ€å°ç°é‡‘ä¸º0
        adjustment = -min_cash + 1  # åŠ 1é¿å…åˆšå¥½ä¸º0
        ini_adjusted = ini + adjustment
        cash_value = ini_adjusted - cum_buy + cum_sell
        print(f"  âš ï¸ åˆå§‹èµ„é‡‘ {ini/1e8:.2f}äº¿ ä¸è¶³ï¼Œå·²è‡ªåŠ¨è°ƒæ•´ä¸º {ini_adjusted/1e8:.2f}äº¿")
    
    # ç¡®ä¿ç°é‡‘éè´Ÿï¼ˆé˜²æ­¢æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜ï¼‰
    cash_value = cash_value.clip(lower=0)
    
    # æ€»èµ„äº§
    total_assets = (stock_value + cash_value).replace(0, pd.NA)

    # å æ¯”
    stock_pct = (stock_value / total_assets * 100.0).fillna(0.0).round(4)
    cash_pct = (cash_value / total_assets * 100.0).fillna(0.0).round(4)

    # æ„å»º DataFrameï¼Œdate ä½œä¸ºç´¢å¼•
    df_result = pd.DataFrame({
        'date': date_range,
        'total_assets': total_assets.fillna(0.0).round(2),  # æ€»èµ„äº§ï¼Œä¿ç•™2ä½å°æ•°
        'stock_pct': stock_pct.values,
        'cash_pct': cash_pct.values,
    })
    df_result.set_index('date', inplace=True)
    
    # å¦‚æœæŒ‡å®šäº†æŠ¥å‘Šå¹´ä»½ï¼Œåªè¿”å›è¯¥å¹´ä»½çš„æ•°æ®
    if report_year:
        # ç­›é€‰è¯¥å¹´ä»½çš„æ—¥æœŸ
        mask = df_result.index.str.startswith(report_year)
        df_filtered = df_result[mask].copy()
        
        if len(df_filtered) > 0:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‰ä¸€å¤©çš„æ•°æ®ä½œä¸ºæœŸåˆï¼ˆè·¨å¹´æƒ…å†µï¼‰
            first_date = df_filtered.index[0]
            if first_date.endswith('-01-01'):
                # è¿™æ˜¯æ–°å¹´ç¬¬ä¸€å¤©ï¼Œå°è¯•è·å–ä¸Šä¸€å¹´æœ€åä¸€å¤©çš„æ•°æ®ä½œä¸º"æœŸåˆæ—¥"
                prev_year = str(int(report_year) - 1)
                prev_last_date = f"{prev_year}-12-31"
                
                if prev_last_date in df_result.index:
                    # å°†ä¸Šä¸€å¹´æœ€åä¸€å¤©æ·»åŠ åˆ°ç»“æœä¸­ï¼Œä½œä¸ºæœŸåˆå‚è€ƒ
                    prev_day_data = df_result.loc[[prev_last_date]].copy()
                    # å°†æ—¥æœŸæ”¹ä¸ºå½“å¹´1æœˆ1æ—¥ï¼Œä½†æ•°æ®ä¿æŒä¸ºä¸Šä¸€å¹´12æœˆ31æ—¥çš„å€¼
                    # è¿™æ ·æœŸåˆèµ„äº§å°±æ˜¯ä¸Šä¸€å¹´çš„æœŸæœ«èµ„äº§
                    prev_day_data.index = [first_date]
                    # ç”¨ä¸Šä¸€å¹´æœ€åä¸€å¤©çš„æ•°æ®è¦†ç›–å½“å¹´ç¬¬ä¸€å¤©çš„æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    df_filtered.loc[first_date] = prev_day_data.loc[first_date]
                    print(f"  ğŸ“… æŠ¥å‘Šå¹´ä»½é™åˆ¶ä¸º {report_year}å¹´")
                    print(f"  æœŸåˆèµ„äº§ä½¿ç”¨ {prev_last_date} æ•°æ®: {prev_day_data.loc[first_date, 'total_assets']/10000:.2f}ä¸‡å…ƒ")
                    print(f"  ç»Ÿè®¡åŒºé—´: {df_filtered.index[0]} è‡³ {df_filtered.index[-1]}")
                else:
                    print(f"  ğŸ“… æŠ¥å‘Šå¹´ä»½é™åˆ¶ä¸º {report_year}å¹´")
                    print(f"  âš ï¸  æœªæ‰¾åˆ° {prev_last_date} æ•°æ®ï¼Œä½¿ç”¨å½“å¹´ç¬¬ä¸€å¤©æ•°æ®ä½œä¸ºæœŸåˆ")
                    print(f"  ç»Ÿè®¡åŒºé—´: {df_filtered.index[0]} è‡³ {df_filtered.index[-1]}")
            else:
                print(f"  ğŸ“… æŠ¥å‘Šå¹´ä»½é™åˆ¶ä¸º {report_year}å¹´")
                print(f"  ç»Ÿè®¡åŒºé—´: {df_filtered.index[0]} è‡³ {df_filtered.index[-1]}")
            
            return df_filtered
        else:
            print(f"  âš ï¸  è­¦å‘Šï¼š{report_year}å¹´æ— äº¤æ˜“æ•°æ®ï¼Œè¿”å›å…¨éƒ¨æ•°æ®")
            return df_result
    
    return df_result


def _ts_code(code: str) -> str:
    """å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸ºTushareæ ¼å¼ï¼ˆ6ä½ä»£ç .å¸‚åœºåç¼€ï¼‰"""
    code = str(code).zfill(6)
    if code.startswith('6'):
        return f"{code}.SH"
    else:
        return f"{code}.SZ"


def _fetch_close_prices_tushare(codes: List[str], start_date: str, end_date: str) -> pd.DataFrame:
    """
    ä½¿ç”¨ Tushare API è·å–è‚¡ç¥¨æ”¶ç›˜ä»·æ•°æ®ï¼ˆä¸å¤æƒï¼‰ã€‚
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
    2. æŒ‰æ—¥æœŸæ‰¹é‡è·å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼ˆè€Œä¸æ˜¯æŒ‰è‚¡ç¥¨é€ä¸ªè·å–ï¼‰
    3. Tushare çš„ daily æ¥å£æ”¯æŒä¸€æ¬¡è·å–å¤šåªè‚¡ç¥¨
    
    å‚æ•°:
        codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆ6ä½å­—ç¬¦ä¸²ï¼‰
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    
    è¿”å›:
        DataFrame: index=date(YYYY-MM-DD), columns=code(6ä½), values=close_price
    """
    if not codes:
        return pd.DataFrame()
    
    if not TUSHARE_TOKEN:
        print("  é”™è¯¯ï¼šæœªè®¾ç½® TUSHARE_TOKEN ç¯å¢ƒå˜é‡")
        return pd.DataFrame()
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"{start_date}_{end_date}"
    cache_file = CACHE_DIR / f"prices_{cache_key}.pkl"
    
    cached_df = None
    if cache_file.exists():
        try:
            print(f"ä»ç¼“å­˜åŠ è½½ä»·æ ¼æ•°æ®: {cache_file.name}")
            cached_df = pd.read_pickle(cache_file)
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦åŒ…å«æ‰€éœ€çš„æ‰€æœ‰è‚¡ç¥¨
            missing_codes = set(codes) - set(cached_df.columns)
            if not missing_codes:
                print(f"  âœ“ ç¼“å­˜å‘½ä¸­ï¼š{len(codes)} åªè‚¡ç¥¨")
                return cached_df[codes]
            print(f"  ç¼“å­˜ä¸­ç¼ºå°‘ {len(missing_codes)} åªè‚¡ç¥¨ï¼Œå°†å¢é‡è·å–")
        except Exception as e:
            print(f"  è­¦å‘Šï¼šè¯»å–ç¼“å­˜å¤±è´¥: {e}")
            cached_df = None
    
    # åˆå§‹åŒ– Tushare
    ts.set_token(TUSHARE_TOKEN)
    pro = ts.pro_api()
    
    # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸º YYYYMMDD
    start_str = start_date.replace('-', '')
    end_str = end_date.replace('-', '')
    
    # ç¡®å®šéœ€è¦è·å–çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ç¼“å­˜ï¼Œåªè·å–ç¼ºå¤±çš„ï¼‰
    codes_to_fetch = codes
    if cached_df is not None:
        missing_codes = list(set(codes) - set(cached_df.columns))
        if missing_codes:
            codes_to_fetch = missing_codes
            print(f"å¢é‡è·å– {len(codes_to_fetch)} åªè‚¡ç¥¨çš„ä»·æ ¼æ•°æ® ({start_date} è‡³ {end_date})...")
        else:
            codes_to_fetch = []
    else:
        print(f"è·å– {len(codes_to_fetch)} åªè‚¡ç¥¨çš„æ”¶ç›˜ä»·æ•°æ® ({start_date} è‡³ {end_date})...")
    
    all_prices = []
    
    if codes_to_fetch:
        # ä¼˜åŒ–ï¼šæ ¹æ®æ—¥æœŸèŒƒå›´åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
        # Tushare å•æ¬¡æœ€å¤šè¿”å›6000æ¡è®°å½•ï¼Œéœ€è¦æ ¹æ®æ—¥æœŸèŒƒå›´è®¡ç®—åˆé€‚çš„æ‰¹æ¬¡å¤§å°
        date_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days + 1
        trading_days_estimate = int(date_days * 0.7)  # ä¼°ç®—äº¤æ˜“æ—¥æ•°ï¼ˆçº¦70%ï¼‰
        
        # åŠ¨æ€æ‰¹æ¬¡å¤§å°ï¼šç¡®ä¿ batch_size Ã— trading_days â‰ˆ 5000ï¼ˆç•™å‡ºä½™é‡ï¼‰
        if trading_days_estimate > 0:
            batch_size = max(10, min(500, 5000 // trading_days_estimate))
        else:
            batch_size = 500
        
        print(f"  é¢„ä¼°äº¤æ˜“æ—¥: {trading_days_estimate} å¤©ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size} åª/æ‰¹")
        
        total_batches = (len(codes_to_fetch) + batch_size - 1) // batch_size
        
        for i in range(0, len(codes_to_fetch), batch_size):
            batch_codes = codes_to_fetch[i:i+batch_size]
            ts_codes = [_ts_code(c) for c in batch_codes]
            
            batch_num = i // batch_size + 1
            print(f"  æ‰¹æ¬¡ {batch_num}/{total_batches}: è·å– {len(batch_codes)} åªè‚¡ç¥¨...", end='', flush=True)
            
            try:
                # ä¸€æ¬¡æ€§è·å–æ•´ä¸ªæ‰¹æ¬¡çš„æ‰€æœ‰æ•°æ®
                df = pro.daily(
                    ts_code=','.join(ts_codes),
                    start_date=start_str,
                    end_date=end_str,
                    fields='ts_code,trade_date,close'
                )
                
                if df is not None and not df.empty:
                    # æ£€æŸ¥æ˜¯å¦è§¦å‘6000æ¡é™åˆ¶
                    returned_stocks = df['ts_code'].nunique()
                    if len(df) >= 6000 and returned_stocks < len(batch_codes):
                        print(f" âš ï¸  è§¦å‘6000æ¡é™åˆ¶({returned_stocks}/{len(batch_codes)}åª)")
                        # è§¦å‘é™åˆ¶ï¼Œæ‹†åˆ†ä¸ºæ›´å°çš„æ‰¹æ¬¡é‡è¯•
                        missing_codes = set(batch_codes) - set(df['ts_code'].str[:6].unique())
                        if missing_codes:
                            print(f"      é‡è¯•è·å– {len(missing_codes)} åªç¼ºå¤±è‚¡ç¥¨...", end='', flush=True)
                            for missing_code in missing_codes:
                                try:
                                    single_df = pro.daily(
                                        ts_code=_ts_code(missing_code),
                                        start_date=start_str,
                                        end_date=end_str,
                                        fields='ts_code,trade_date,close'
                                    )
                                    if single_df is not None and not single_df.empty:
                                        df = pd.concat([df, single_df], ignore_index=True)
                                    time.sleep(0.1)
                                except:
                                    pass
                            print(f" âœ“ è¡¥å……å®Œæˆ")
                    
                    # è½¬æ¢ä»£ç æ ¼å¼ï¼ˆå»æ‰å¸‚åœºåç¼€ï¼‰
                    df['code'] = df['ts_code'].str[:6]
                    # è½¬æ¢æ—¥æœŸæ ¼å¼
                    df['date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d').dt.strftime('%Y-%m-%d')
                    # åªä¿ç•™éœ€è¦çš„åˆ—
                    df = df[['date', 'code', 'close']]
                    all_prices.append(df)
                    final_stocks = df['code'].nunique()
                    print(f" âœ“ è·å– {len(df)} æ¡è®°å½• ({final_stocks} åªè‚¡ç¥¨)")
                else:
                    print(" âœ— æ— æ•°æ®")
                
                # API é™æµï¼šæ¯åˆ†é’Ÿæœ€å¤š200æ¬¡è°ƒç”¨ï¼Œé€‚å½“å»¶è¿Ÿ
                if batch_num < total_batches:
                    time.sleep(0.3)  # æ¯æ‰¹æ¬¡å»¶è¿Ÿ300msï¼Œç¡®ä¿ä¸è¶…è¿‡é™æµ
            
            except Exception as e:
                print(f" âœ— é”™è¯¯: {e}")
                continue
    
    # åˆå¹¶æ–°è·å–çš„æ•°æ®å’Œç¼“å­˜æ•°æ®
    if all_prices:
        # æ–°è·å–çš„æ•°æ®
        new_df = pd.concat(all_prices, ignore_index=True)
        new_pivot = new_df.pivot(index='date', columns='code', values='close')
        print(f"  âœ“ æ–°æ•°æ®ï¼š{len(new_pivot)} ä¸ªäº¤æ˜“æ—¥ Ã— {len(new_pivot.columns)} åªè‚¡ç¥¨")
        
        # ä¸ç¼“å­˜åˆå¹¶
        if cached_df is not None:
            price_pivot = pd.concat([cached_df, new_pivot], axis=1)
            # å»é‡åˆ—ï¼ˆä¿ç•™æ–°æ•°æ®ï¼‰
            price_pivot = price_pivot.loc[:, ~price_pivot.columns.duplicated(keep='last')]
            print(f"  âœ“ åˆå¹¶åï¼š{len(price_pivot)} ä¸ªäº¤æ˜“æ—¥ Ã— {len(price_pivot.columns)} åªè‚¡ç¥¨")
        else:
            price_pivot = new_pivot
    elif cached_df is not None:
        # æ²¡æœ‰æ–°æ•°æ®ï¼Œåªä½¿ç”¨ç¼“å­˜
        price_pivot = cached_df
    else:
        print("  é”™è¯¯ï¼šæœªèƒ½è·å–ä»»ä½•ä»·æ ¼æ•°æ®")
        return pd.DataFrame()
    
    # ä¿å­˜åˆ°ç¼“å­˜
    try:
        price_pivot.to_pickle(cache_file)
        print(f"  å·²ç¼“å­˜åˆ°: {cache_file.name}")
    except Exception as e:
        print(f"  è­¦å‘Šï¼šç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    return price_pivot


def _build_price_from_trades(df: pd.DataFrame, codes: List[str], date_range: pd.Index) -> pd.DataFrame:
    """
    ä»äº¤å‰²å•ä¸­æ„å»ºæ¯æ—¥ä»·æ ¼æ•°æ®ï¼ˆä½¿ç”¨å½“å¤©æœ€åä¸€ç¬”äº¤æ˜“çš„ä»·æ ¼ä½œä¸ºæ”¶ç›˜ä»·ï¼‰ã€‚
    
    å¯¹äºé«˜é¢‘äº¤æ˜“ç­–ç•¥ï¼Œä½¿ç”¨å®é™…æˆäº¤ä»·æ¯”Tushareçš„å¤æƒä»·æ ¼æ›´å‡†ç¡®ã€‚
    
    ä¼˜åŒ–ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼Œé¿å…é€ä¸ªè‚¡ç¥¨å¾ªç¯ã€‚
    
    å‚æ•°:
        df: äº¤å‰²å•DataFrameï¼ˆéœ€åŒ…å«buy_dt, sell_dt, code, buy_price, sell_priceåˆ—ï¼‰
        codes: éœ€è¦ä»·æ ¼çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        date_range: æ—¥æœŸèŒƒå›´
    
    è¿”å›:
        DataFrame: index=date, columns=code, values=price
    """
    # ç­›é€‰å‡ºéœ€è¦çš„è‚¡ç¥¨ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼‰
    codes_set = set(codes)
    df_filtered = df[df['code'].isin(codes_set)].copy()
    
    if df_filtered.empty:
        return pd.DataFrame(index=date_range)
    
    # å‡†å¤‡ä¹°å…¥ä»·æ ¼æ•°æ®
    buy_data = df_filtered.dropna(subset=['buy_dt']).copy()
    buy_data['date'] = buy_data['buy_dt'].dt.strftime('%Y-%m-%d')
    buy_data['code_str'] = buy_data['code'].astype(str).str.zfill(6)
    
    # å‡†å¤‡å–å‡ºä»·æ ¼æ•°æ®
    sell_data = df_filtered.dropna(subset=['sell_dt']).copy()
    sell_data['date'] = sell_data['sell_dt'].dt.strftime('%Y-%m-%d')
    sell_data['code_str'] = sell_data['code'].astype(str).str.zfill(6)
    
    # ä½¿ç”¨groupbyä¸€æ¬¡æ€§è·å–æ¯å¤©æ¯åªè‚¡ç¥¨çš„æœ€åä¸€ç¬”ä»·æ ¼
    if not buy_data.empty:
        # ä¹°å…¥ä»·ï¼šæ¯å¤©æ¯åªè‚¡ç¥¨çš„æœ€åä¸€ç¬”
        buy_last = buy_data.groupby(['date', 'code_str'])['buy_price'].last().reset_index()
        buy_pivot = buy_last.pivot(index='date', columns='code_str', values='buy_price')
    else:
        buy_pivot = pd.DataFrame()
    
    if not sell_data.empty:
        # å–å‡ºä»·ï¼šæ¯å¤©æ¯åªè‚¡ç¥¨çš„æœ€åä¸€ç¬”
        sell_last = sell_data.groupby(['date', 'code_str'])['sell_price'].last().reset_index()
        sell_pivot = sell_last.pivot(index='date', columns='code_str', values='sell_price')
    else:
        sell_pivot = pd.DataFrame()
    
    # åˆå¹¶ï¼šå–å‡ºä»·ä¼˜å…ˆï¼ˆæ›´æ¥è¿‘æ”¶ç›˜ä»·ï¼‰
    if not buy_pivot.empty and not sell_pivot.empty:
        price_df = buy_pivot.combine_first(sell_pivot)
        price_df.update(sell_pivot)  # å–å‡ºä»·è¦†ç›–ä¹°å…¥ä»·
    elif not sell_pivot.empty:
        price_df = sell_pivot
    elif not buy_pivot.empty:
        price_df = buy_pivot
    else:
        price_df = pd.DataFrame()
    
    # å¯¹é½æ—¥æœŸèŒƒå›´
    price_df = price_df.reindex(index=date_range, columns=[str(c).zfill(6) for c in codes])
    price_df.index.name = 'date'
    
    # å‰å‘å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“ä»·æ ¼ï¼‰
    price_df = price_df.ffill()
    
    # å¦‚æœè¿˜æœ‰ç¼ºå¤±ï¼ˆæŸäº›è‚¡ç¥¨åœ¨åˆæœŸæ²¡æœ‰äº¤æ˜“ï¼‰ï¼Œç”¨åå‘å¡«å……
    price_df = price_df.bfill()
    
    # å¦‚æœè¿˜æœ‰ç¼ºå¤±ï¼Œå¡«0
    price_df = price_df.fillna(0.0)
    
    return price_df
